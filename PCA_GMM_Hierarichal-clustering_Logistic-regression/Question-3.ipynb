{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import os\n",
    "import math\n",
    "import operator\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from statistics import stdev,mean\n",
    "import scipy.stats as ss\n",
    "from sklearn.metrics import f1_score,precision_score,recall_score,accuracy_score,roc_curve,roc_auc_score,confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 0\n",
    "#k , l , m testing\n",
    "def one_vs_all(data,y,epochs,lrate):\n",
    "    classes = list(set(y))\n",
    "    num_classes = len(classes)\n",
    "    W = np.zeros((num_classes,data.shape[1]))\n",
    "    k = 1\n",
    "    print(data.shape[1])\n",
    "    for itr in range(epochs):\n",
    "        k = 2\n",
    "        for c in range(num_classes):\n",
    "            w = W[c]\n",
    "            vecj = np.zeros(data.shape[1])\n",
    "            k = 3\n",
    "            for n in range(data.shape[0]):\n",
    "                k = 4\n",
    "                del_j = 0\n",
    "                m = math.exp(np.matmul(data[n,:], np.transpose(w)))\n",
    "                csum = 0\n",
    "                for aux_c in range(num_classes):\n",
    "                    k = 5\n",
    "                    csum += math.exp(np.matmul(data[n,:] ,np.transpose(W[aux_c])))\n",
    "                m /= csum\n",
    "                del_j += m\n",
    "                k = 6\n",
    "                if(y[n] == classes[c]):\n",
    "                    del_j -= 1\n",
    "\n",
    "\n",
    "                l = 1    \n",
    "                for i in range(data.shape[1]):\n",
    "                    l = 2\n",
    "                    vecj[i] += data[n,i]*del_j*lrate\n",
    "\n",
    "            for i in range(len(w)):\n",
    "                m = 1\n",
    "                w[i] -= vecj[i]\n",
    "\n",
    "                # normalizing w\n",
    "            sqsum = 0\n",
    "            for i in range(len(w)):\n",
    "                sqsum += w[i]**2\n",
    "            for i in range(len(w)):\n",
    "                w[i] /= np.sqrt(sqsum)\n",
    "\n",
    "            for i in range(len(w)):\n",
    "                W[c][i] = w[i]\n",
    "\n",
    "    return W, classes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Predict(inst,mean,std):\n",
    "    inst = (inst-mean)/std\n",
    "    inst1 = np.concatenate((np.array([1.0 for i in range(inst.shape[0])])[:, np.newaxis], inst), axis=1)\n",
    "    inst2 = np.array(inst1,dtype=float)\n",
    "    out = []\n",
    "    for w in W:\n",
    "        out.append(np.exp(np.dot(inst2,np.transpose(w))))\n",
    "    return out\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "wine = pd.read_csv(\"./wine-quality/data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_adm = wine.quality.values\n",
    "X_adm = wine.iloc[:,:]\n",
    "X_adm_train,X_adm_val,y_adm_train,y_adm_val=train_test_split(X_adm,y_adm,test_size=0.2,random_state=42)\n",
    "X_train_temp = X_adm_train\n",
    "X_adm_train = X_adm_train.drop('quality',axis = 1)\n",
    "X_adm_val= X_adm_val.drop('quality',axis = 1)\n",
    "X_adm_train=X_adm_train.values\n",
    "X_adm_val=X_adm_val.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, ' ', 17)\n",
      "(4, ' ', 150)\n",
      "(5, ' ', 1311)\n",
      "(6, ' ', 1987)\n",
      "(7, ' ', 785)\n",
      "(8, ' ', 153)\n",
      "(9, ' ', 5)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for C in list(set(y_adm)):\n",
    "    print(C,\" \",wine[wine[\"quality\"]== C].shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "Mean,Std=np.mean((X_adm_train),0),np.std((X_adm_train),0)\n",
    "X_adm_train=(X_adm_train - Mean)/Std\n",
    "X_adm_train = np.concatenate((np.array([1.0 for i in range(X_adm_train.shape[0])])[:, np.newaxis], X_adm_train), axis=1)\n",
    "#X_adm_val = np.concatenate((np.array([1.0 for i in range(X_adm_val.shape[0])])[:, np.newaxis], X_adm_val), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n"
     ]
    }
   ],
   "source": [
    "W, classes = one_vs_all(X_adm_train,y_adm_train,100,0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_Class = Predict(X_adm_val,Mean,Std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(np.array(out_Class))\n",
    "Ind = np.argmax(out_Class, axis=0)\n",
    "pred = []\n",
    "for ind in Ind:\n",
    "    pred.append(classes[ind])\n",
    "#print(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('F1-score', 0.4875283446712018)\n",
      "('precision', 0.4875283446712018)\n",
      "('Accuracy', 0.4875283446712018)\n",
      "('Recall', 0.4875283446712018)\n"
     ]
    }
   ],
   "source": [
    "print(\"F1-score\",f1_score(y_adm_val,pred, average = 'micro'))\n",
    "print(\"precision\",precision_score(y_adm_val,pred, average = 'micro'))\n",
    "print(\"Accuracy\",accuracy_score(y_adm_val,pred))\n",
    "print(\"Recall\",recall_score(y_adm_val,pred, average = 'micro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logistic_regression(data,y,epochs,lrate):\n",
    "    Temp_data = np.concatenate((np.array([1.0 for i in range(data.shape[0])])[:, np.newaxis], data), axis=1)\n",
    "    theta = np.zeros(Temp_data.shape[1])\n",
    "    theta[0] = 1\n",
    "    x = 1\n",
    "    for i in range(epochs):\n",
    "        x = x+1\n",
    "        z = np.dot(Temp_data,theta)\n",
    "        h = 1 / (1 + np.exp(-z))\n",
    "        gradient = np.dot(Temp_data.T, (h - y)) / y.size\n",
    "        theta -= lrate * gradient\n",
    "    return theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(inst,theta,key,k,threshold,mean,std):\n",
    "    #print(Mean.shape,inst.shape)\n",
    "    inst = (inst-mean)/std\n",
    "    inst1 = np.concatenate((np.array([1.0 for i in range(inst.shape[0])])[:, np.newaxis], inst), axis=1)\n",
    "    inst2 = np.array(inst1,dtype=float)\n",
    "    #print(inst.shape,theta.shape)\n",
    "    prob = 1 / (1 + np.exp(-1*np.dot(inst2, theta)))\n",
    "    Out = []\n",
    "    v1 = 0\n",
    "    for p in prob:\n",
    "        v1 = v1 + 1\n",
    "        if(p >= threshold and key>k):\n",
    "            Out.append(key)\n",
    "        elif(p < threshold and key<k):\n",
    "            Out.append(key)\n",
    "        else:\n",
    "            Out.append(k)\n",
    "    return Out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_subtable(df, node,class1,class2):\n",
    "    return df[operator.or_(df[node] == class1,df[node] == class2)].reset_index(drop=True)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_vs_one(df,y,epochs,lrate):\n",
    "    classes = list(set(y))\n",
    "    num_classes = len(classes)\n",
    "    Dict = {}\n",
    "    for i in range(num_classes):\n",
    "        Dict[classes[i]] = {}\n",
    "        for j in range(i+1,num_classes): \n",
    "            temp = get_subtable(df,\"quality\",classes[i],classes[j]).values\n",
    "            Dict[classes[i]][classes[j]] = logistic_regression(temp[:,:-1],temp[:,-1],epochs,lrate)\n",
    "    return Dict\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_class(inst,threshold,mean,std):\n",
    "    arr_class = []\n",
    "    for key in Dict.keys():\n",
    "        for k in Dict[key].keys():\n",
    "            arr_class.append(predict(inst,Dict[key][k],key,k,threshold,mean,std))\n",
    "    return np.array(arr_class)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "Dict = one_vs_one(X_train_temp,y_adm_train,100,0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr_class = get_class(X_adm_val,0.4,Mean,Std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(arr_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred1 = []\n",
    "for i in range(arr_class.shape[1]):\n",
    "    (values,counts) = np.unique(arr_class[:,i],return_counts=True)\n",
    "    ind=np.argmax(counts)\n",
    "    #print(values[ind])\n",
    "    pred1.append(values[ind])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 3\n",
      "7 9\n",
      "7 9\n",
      "6 9\n",
      "6 3\n",
      "6 9\n",
      "5 3\n",
      "6 9\n",
      "6 3\n",
      "5 9\n",
      "5 3\n",
      "6 9\n",
      "6 9\n",
      "5 9\n",
      "6 9\n",
      "6 9\n",
      "6 9\n",
      "5 3\n",
      "6 9\n",
      "4 3\n",
      "5 9\n",
      "8 3\n",
      "5 9\n",
      "5 3\n",
      "6 3\n",
      "5 3\n",
      "3 3\n",
      "7 9\n",
      "5 9\n",
      "6 9\n",
      "6 3\n",
      "5 9\n",
      "6 9\n",
      "6 3\n",
      "5 3\n",
      "6 3\n",
      "7 3\n",
      "5 9\n",
      "5 9\n",
      "6 9\n",
      "6 3\n",
      "5 9\n",
      "6 3\n",
      "6 3\n",
      "6 3\n",
      "5 9\n",
      "6 9\n",
      "6 3\n",
      "6 3\n",
      "6 9\n",
      "7 9\n",
      "5 9\n",
      "6 3\n",
      "6 9\n",
      "6 3\n",
      "6 9\n",
      "6 3\n",
      "3 9\n",
      "6 9\n",
      "6 3\n",
      "6 9\n",
      "6 3\n",
      "6 9\n",
      "7 9\n",
      "6 3\n",
      "7 9\n",
      "7 9\n",
      "6 9\n",
      "7 9\n",
      "6 3\n",
      "6 3\n",
      "5 3\n",
      "5 3\n",
      "6 9\n",
      "5 3\n",
      "5 3\n",
      "6 9\n",
      "5 3\n",
      "6 9\n",
      "5 3\n",
      "8 3\n",
      "5 9\n",
      "5 3\n",
      "6 3\n",
      "6 9\n",
      "5 9\n",
      "5 9\n",
      "6 9\n",
      "6 9\n",
      "7 3\n",
      "5 3\n",
      "5 9\n",
      "7 3\n",
      "5 9\n",
      "6 9\n",
      "6 9\n",
      "6 9\n",
      "6 3\n",
      "6 3\n",
      "7 9\n",
      "4 3\n",
      "5 9\n",
      "5 9\n",
      "6 9\n",
      "6 3\n",
      "6 3\n",
      "6 3\n",
      "6 3\n",
      "5 3\n",
      "4 3\n",
      "7 3\n",
      "6 9\n",
      "6 9\n",
      "5 9\n",
      "5 9\n",
      "5 9\n",
      "7 3\n",
      "6 9\n",
      "5 9\n",
      "6 9\n",
      "5 3\n",
      "7 3\n",
      "5 3\n",
      "7 3\n",
      "6 9\n",
      "6 9\n",
      "5 9\n",
      "5 3\n",
      "6 9\n",
      "5 9\n",
      "5 9\n",
      "8 3\n",
      "6 3\n",
      "6 3\n",
      "6 3\n",
      "6 3\n",
      "6 9\n",
      "6 9\n",
      "6 3\n",
      "6 9\n",
      "5 9\n",
      "4 3\n",
      "5 9\n",
      "7 9\n",
      "7 3\n",
      "5 3\n",
      "5 9\n",
      "6 3\n",
      "7 3\n",
      "7 3\n",
      "7 9\n",
      "6 9\n",
      "4 9\n",
      "5 9\n",
      "7 9\n",
      "6 3\n",
      "6 9\n",
      "6 9\n",
      "5 3\n",
      "5 9\n",
      "5 3\n",
      "5 3\n",
      "7 3\n",
      "6 3\n",
      "5 9\n",
      "7 3\n",
      "5 9\n",
      "6 9\n",
      "6 9\n",
      "5 3\n",
      "5 9\n",
      "7 3\n",
      "6 9\n",
      "6 3\n",
      "5 9\n",
      "5 3\n",
      "6 3\n",
      "6 9\n",
      "7 9\n",
      "4 9\n",
      "5 9\n",
      "5 3\n",
      "8 3\n",
      "7 3\n",
      "5 9\n",
      "7 3\n",
      "7 3\n",
      "6 3\n",
      "5 9\n",
      "6 3\n",
      "6 9\n",
      "6 9\n",
      "6 3\n",
      "5 3\n",
      "5 9\n",
      "6 9\n",
      "6 9\n",
      "7 3\n",
      "6 3\n",
      "7 9\n",
      "6 9\n",
      "5 9\n",
      "7 9\n",
      "6 9\n",
      "6 9\n",
      "5 3\n",
      "6 3\n",
      "6 9\n",
      "5 9\n",
      "6 3\n",
      "6 9\n",
      "5 9\n",
      "6 9\n",
      "5 9\n",
      "6 9\n",
      "8 3\n",
      "6 3\n",
      "6 9\n",
      "5 9\n",
      "6 9\n",
      "6 3\n",
      "6 9\n",
      "6 3\n",
      "6 3\n",
      "8 3\n",
      "5 3\n",
      "7 3\n",
      "7 9\n",
      "6 3\n",
      "5 9\n",
      "5 3\n",
      "8 9\n",
      "6 9\n",
      "7 3\n",
      "7 9\n",
      "5 3\n",
      "5 9\n",
      "5 9\n",
      "5 9\n",
      "6 9\n",
      "6 9\n",
      "5 9\n",
      "7 9\n",
      "6 5\n",
      "6 9\n",
      "8 3\n",
      "4 3\n",
      "6 9\n",
      "6 3\n",
      "7 9\n",
      "4 3\n",
      "8 9\n",
      "7 3\n",
      "5 9\n",
      "6 3\n",
      "6 9\n",
      "5 3\n",
      "6 3\n",
      "5 9\n",
      "5 9\n",
      "4 9\n",
      "6 3\n",
      "6 9\n",
      "6 3\n",
      "6 3\n",
      "5 3\n",
      "6 3\n",
      "5 3\n",
      "6 3\n",
      "6 3\n",
      "5 3\n",
      "5 9\n",
      "6 9\n",
      "5 9\n",
      "6 9\n",
      "6 3\n",
      "6 9\n",
      "6 3\n",
      "6 3\n",
      "6 3\n",
      "7 9\n",
      "5 3\n",
      "6 3\n",
      "5 9\n",
      "6 3\n",
      "7 9\n",
      "5 9\n",
      "7 3\n",
      "5 3\n",
      "5 9\n",
      "8 9\n",
      "5 9\n",
      "6 9\n",
      "5 3\n",
      "6 3\n",
      "8 9\n",
      "7 3\n",
      "5 9\n",
      "7 3\n",
      "6 3\n",
      "4 3\n",
      "5 9\n",
      "6 3\n",
      "6 3\n",
      "6 9\n",
      "3 9\n",
      "6 3\n",
      "7 9\n",
      "5 9\n",
      "6 3\n",
      "6 3\n",
      "6 9\n",
      "7 3\n",
      "7 3\n",
      "5 9\n",
      "5 9\n",
      "4 3\n",
      "5 3\n",
      "7 9\n",
      "6 3\n",
      "5 9\n",
      "6 9\n",
      "6 3\n",
      "7 9\n",
      "4 9\n",
      "5 9\n",
      "7 3\n",
      "6 9\n",
      "7 9\n",
      "7 9\n",
      "6 3\n",
      "6 3\n",
      "7 3\n",
      "6 9\n",
      "5 3\n",
      "8 3\n",
      "6 9\n",
      "6 3\n",
      "4 9\n",
      "8 3\n",
      "6 3\n",
      "4 3\n",
      "7 9\n",
      "7 3\n",
      "7 3\n",
      "6 3\n",
      "6 3\n",
      "6 9\n",
      "7 3\n",
      "6 9\n",
      "5 9\n",
      "6 3\n",
      "6 3\n",
      "5 3\n",
      "6 9\n",
      "6 9\n",
      "6 9\n",
      "6 9\n",
      "6 3\n",
      "7 9\n",
      "5 3\n",
      "4 3\n",
      "5 9\n",
      "5 3\n",
      "6 3\n",
      "6 3\n",
      "5 9\n",
      "7 9\n",
      "5 9\n",
      "6 9\n",
      "6 3\n",
      "5 9\n",
      "5 3\n",
      "6 3\n",
      "5 9\n",
      "6 9\n",
      "6 9\n",
      "6 3\n",
      "5 9\n",
      "6 3\n",
      "8 9\n",
      "5 3\n",
      "6 9\n",
      "8 3\n",
      "5 3\n",
      "5 9\n",
      "5 9\n",
      "5 3\n",
      "6 3\n",
      "6 3\n",
      "8 3\n",
      "5 3\n",
      "6 3\n",
      "5 3\n",
      "6 9\n",
      "6 9\n",
      "5 3\n",
      "8 9\n",
      "5 9\n",
      "6 3\n",
      "5 9\n",
      "5 9\n",
      "6 3\n",
      "6 3\n",
      "7 3\n",
      "6 3\n",
      "6 9\n",
      "3 9\n",
      "6 3\n",
      "4 9\n",
      "5 9\n",
      "6 9\n",
      "7 9\n",
      "8 9\n",
      "6 3\n",
      "6 3\n",
      "5 9\n",
      "6 9\n",
      "6 3\n",
      "7 8\n",
      "6 9\n",
      "4 9\n",
      "6 3\n",
      "7 3\n",
      "7 3\n",
      "7 9\n",
      "5 9\n",
      "6 3\n",
      "7 8\n",
      "6 9\n",
      "5 3\n",
      "7 9\n",
      "7 9\n",
      "6 9\n",
      "6 3\n",
      "5 9\n",
      "6 9\n",
      "7 3\n",
      "7 3\n",
      "6 3\n",
      "7 3\n",
      "6 3\n",
      "6 9\n",
      "7 9\n",
      "5 3\n",
      "6 9\n",
      "5 3\n",
      "6 9\n",
      "6 9\n",
      "8 3\n",
      "5 9\n",
      "6 3\n",
      "7 3\n",
      "6 3\n",
      "6 3\n",
      "6 9\n",
      "5 9\n",
      "6 9\n",
      "6 9\n",
      "6 3\n",
      "8 9\n",
      "5 9\n",
      "8 9\n",
      "5 3\n",
      "6 3\n",
      "7 3\n",
      "7 9\n",
      "5 9\n",
      "4 3\n",
      "5 3\n",
      "5 9\n",
      "6 9\n",
      "5 9\n",
      "6 9\n",
      "6 3\n",
      "6 3\n",
      "6 3\n",
      "6 9\n",
      "5 9\n",
      "7 3\n",
      "5 9\n",
      "6 9\n",
      "6 3\n",
      "6 9\n",
      "8 3\n",
      "5 9\n",
      "5 3\n",
      "7 9\n",
      "5 3\n",
      "7 9\n",
      "7 3\n",
      "5 9\n",
      "5 9\n",
      "6 3\n",
      "6 9\n",
      "5 3\n",
      "7 9\n",
      "5 3\n",
      "6 3\n",
      "7 9\n",
      "5 3\n",
      "7 9\n",
      "6 3\n",
      "6 3\n",
      "6 9\n",
      "5 9\n",
      "6 9\n",
      "7 3\n",
      "5 9\n",
      "5 9\n",
      "4 3\n",
      "8 9\n",
      "5 3\n",
      "7 3\n",
      "5 9\n",
      "7 3\n",
      "6 3\n",
      "5 3\n",
      "6 9\n",
      "7 9\n",
      "5 9\n",
      "5 3\n",
      "7 3\n",
      "7 3\n",
      "6 9\n",
      "4 3\n",
      "6 3\n",
      "6 3\n",
      "7 3\n",
      "7 9\n",
      "7 9\n",
      "5 3\n",
      "6 9\n",
      "8 9\n",
      "6 9\n",
      "6 3\n",
      "7 9\n",
      "6 9\n",
      "6 3\n",
      "6 3\n",
      "7 3\n",
      "5 9\n",
      "6 9\n",
      "6 9\n",
      "5 3\n",
      "6 9\n",
      "7 3\n",
      "5 3\n",
      "6 3\n",
      "6 9\n",
      "6 9\n",
      "6 9\n",
      "5 9\n",
      "7 3\n",
      "6 3\n",
      "6 9\n",
      "6 9\n",
      "6 9\n",
      "5 9\n",
      "7 3\n",
      "8 9\n",
      "6 3\n",
      "5 9\n",
      "7 3\n",
      "6 9\n",
      "7 9\n",
      "6 3\n",
      "5 9\n",
      "6 3\n",
      "7 9\n",
      "5 3\n",
      "5 9\n",
      "6 9\n",
      "6 9\n",
      "5 3\n",
      "8 3\n",
      "6 9\n",
      "7 9\n",
      "7 9\n",
      "5 3\n",
      "8 3\n",
      "6 3\n",
      "6 3\n",
      "6 3\n",
      "5 3\n",
      "7 9\n",
      "6 3\n",
      "5 9\n",
      "6 3\n",
      "6 3\n",
      "5 9\n",
      "7 9\n",
      "6 3\n",
      "6 3\n",
      "6 9\n",
      "5 3\n",
      "4 3\n",
      "6 9\n",
      "5 9\n",
      "4 3\n",
      "6 3\n",
      "6 9\n",
      "5 9\n",
      "5 9\n",
      "5 9\n",
      "3 3\n",
      "5 9\n",
      "5 9\n",
      "6 3\n",
      "6 3\n",
      "5 9\n",
      "5 9\n",
      "7 3\n",
      "6 3\n",
      "5 3\n",
      "4 9\n",
      "6 9\n",
      "6 3\n",
      "6 3\n",
      "7 3\n",
      "5 9\n",
      "6 9\n",
      "7 9\n",
      "5 9\n",
      "6 9\n",
      "5 9\n",
      "4 9\n",
      "6 3\n",
      "4 3\n",
      "6 3\n",
      "5 3\n",
      "5 9\n",
      "6 3\n",
      "6 3\n",
      "6 3\n",
      "4 9\n",
      "4 9\n",
      "6 9\n",
      "6 9\n",
      "6 3\n",
      "6 3\n",
      "6 9\n",
      "6 9\n",
      "4 3\n",
      "7 9\n",
      "6 9\n",
      "6 9\n",
      "5 3\n",
      "7 9\n",
      "4 3\n",
      "6 3\n",
      "7 9\n",
      "6 3\n",
      "6 9\n",
      "7 3\n",
      "5 3\n",
      "6 3\n",
      "7 3\n",
      "6 9\n",
      "6 9\n",
      "7 3\n",
      "5 3\n",
      "6 3\n",
      "6 3\n",
      "5 3\n",
      "5 3\n",
      "5 9\n",
      "6 3\n",
      "8 9\n",
      "6 9\n",
      "6 9\n",
      "7 3\n",
      "7 9\n",
      "6 9\n",
      "7 3\n",
      "4 3\n",
      "7 3\n",
      "6 3\n",
      "5 3\n",
      "6 3\n",
      "7 9\n",
      "7 3\n",
      "6 9\n",
      "6 3\n",
      "6 3\n",
      "6 3\n",
      "6 3\n",
      "5 3\n",
      "6 3\n",
      "6 9\n",
      "7 3\n",
      "5 3\n",
      "6 3\n",
      "6 9\n",
      "7 6\n",
      "6 9\n",
      "6 9\n",
      "6 3\n",
      "6 3\n",
      "6 9\n",
      "6 9\n",
      "7 3\n",
      "7 9\n",
      "4 9\n",
      "6 3\n",
      "6 9\n",
      "5 9\n",
      "6 3\n",
      "6 3\n",
      "6 3\n",
      "5 3\n",
      "8 3\n",
      "4 3\n",
      "6 3\n",
      "7 3\n",
      "6 9\n",
      "5 3\n",
      "6 9\n",
      "6 3\n",
      "6 3\n",
      "5 3\n",
      "6 9\n",
      "6 3\n",
      "6 3\n",
      "6 9\n",
      "6 3\n",
      "5 9\n",
      "5 3\n",
      "5 9\n",
      "5 9\n",
      "5 9\n",
      "8 3\n",
      "5 9\n",
      "5 3\n",
      "6 9\n",
      "6 3\n",
      "7 3\n",
      "6 9\n",
      "5 9\n",
      "7 9\n",
      "7 3\n",
      "6 9\n",
      "6 9\n",
      "5 3\n",
      "6 3\n",
      "5 9\n",
      "5 9\n",
      "5 3\n",
      "6 3\n",
      "6 3\n",
      "6 9\n",
      "5 3\n",
      "5 9\n",
      "6 3\n",
      "6 3\n",
      "6 3\n",
      "6 3\n",
      "5 9\n",
      "7 3\n",
      "6 9\n",
      "5 3\n",
      "5 3\n",
      "6 8\n",
      "6 9\n",
      "6 3\n",
      "6 9\n",
      "7 3\n",
      "5 3\n",
      "6 9\n",
      "5 9\n",
      "6 3\n",
      "8 3\n",
      "5 3\n",
      "5 9\n",
      "6 3\n",
      "6 3\n",
      "6 3\n",
      "6 3\n",
      "5 9\n",
      "6 9\n",
      "8 9\n",
      "5 3\n",
      "6 9\n",
      "7 9\n",
      "5 9\n",
      "6 3\n",
      "5 3\n",
      "5 3\n",
      "6 9\n",
      "6 3\n",
      "6 9\n",
      "4 9\n",
      "7 3\n",
      "5 3\n",
      "6 9\n",
      "5 9\n",
      "6 3\n",
      "6 3\n",
      "7 3\n",
      "6 9\n",
      "5 3\n",
      "6 3\n",
      "5 3\n",
      "7 9\n",
      "7 9\n",
      "6 9\n",
      "6 3\n",
      "6 9\n",
      "5 9\n",
      "4 3\n",
      "5 3\n",
      "7 3\n",
      "6 3\n",
      "8 3\n",
      "8 9\n",
      "6 9\n",
      "7 9\n",
      "6 3\n",
      "5 3\n",
      "6 3\n",
      "5 9\n",
      "6 9\n",
      "6 3\n",
      "6 9\n",
      "8 3\n",
      "8 9\n",
      "6 3\n",
      "6 3\n",
      "8 3\n",
      "5 9\n",
      "5 9\n",
      "6 9\n",
      "6 3\n",
      "6 3\n",
      "7 3\n",
      "7 3\n",
      "6 3\n",
      "6 9\n",
      "7 3\n",
      "6 3\n",
      "5 3\n",
      "7 9\n",
      "6 3\n",
      "6 9\n",
      "5 9\n",
      "5 3\n",
      "5 9\n",
      "5 9\n",
      "7 9\n",
      "7 9\n",
      "7 3\n",
      "6 3\n",
      "5 3\n",
      "5 9\n",
      "6 3\n",
      "5 9\n",
      "6 3\n",
      "5 9\n",
      "6 9\n",
      "6 3\n",
      "5 3\n",
      "6 3\n",
      "6 9\n",
      "5 9\n",
      "6 3\n",
      "6 3\n",
      "7 3\n",
      "7 3\n",
      "5 9\n",
      "5 9\n",
      "6 9\n",
      "7 9\n",
      "6 9\n",
      "6 3\n",
      "6 3\n",
      "6 9\n",
      "6 9\n",
      "5 9\n",
      "8 9\n",
      "5 9\n",
      "7 3\n",
      "6 9\n"
     ]
    }
   ],
   "source": [
    "for i in range(X_adm_val.shape[0]):\n",
    "    print(y_adm_val[i],pred1[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-score 0.0022675736961451248\n",
      "precision 0.0022675736961451248\n",
      "Accuracy 0.0022675736961451248\n",
      "Recall 0.0022675736961451248\n"
     ]
    }
   ],
   "source": [
    "print(\"F1-score\",f1_score(y_adm_val,pred1, average = 'micro'))\n",
    "print(\"precision\",precision_score(y_adm_val,pred1, average = 'micro'))\n",
    "print(\"Accuracy\",accuracy_score(y_adm_val,pred1))\n",
    "print(\"Recall\",recall_score(y_adm_val,pred1, average = 'micro'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
